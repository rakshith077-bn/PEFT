# Introduction
The core idea of ViT is to treat an image as a sequence of fixed-size patches, which are then flattended and convereted into 1D vectors. These patches are subsequently processed by a transformer encoder, which enables the model to capture global context and dependencies across the entire image. 

By dividing the images into patches, ViT effectively reduces the computational complexity of handling large images while retaining the ability to model complex spatial interaction.




